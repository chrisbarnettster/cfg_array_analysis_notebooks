{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# check z-score and features of SNA data\n",
    "\n",
    "as per http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459425/#SD2\n",
    "\n",
    "also see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3097418/ for suggestions on analysis of glycan arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z-score as the statistical test for significance of a sample\n",
    "In the paper by Cholleti and Cummings http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3459425/#SD2\n",
    "\n",
    "> \"To avoid using an arbitrary threshold in determining binders and non-binders, we used the z-score as the statistical test for significance of a sample. The z-score transformation is calculated by comparing the value of a sample, relative to the sample mean and standard deviation, with the null hypothesis being that a random sample pulled from the population would be a non-binder. If the converted p value is less than 0.15, the null hypothesis is rejected and the sample is considered a binding glycan. We used a non-conservative p value to allow more glycans in the list of candidate binders as an input to GLYMMR. The z-score transformation is based on the sum of the RFU intensity values for the three different concentrations of the glycan. This statistical test allows the program to discard not only non-binding glycans, but glycans that exhibit non-specific binding, which could distort the motif discovery algorithm. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## House keeping tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### import all required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import urllib2\n",
    "import os\n",
    "import json\n",
    "import StringIO\n",
    "import pickle\n",
    "\n",
    "# dataframe and numerical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#scipy\n",
    "from scipy import stats\n",
    "from scipy.special import erf\n",
    "from scipy import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "def addToggle():\n",
    "    return '''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.'''\n",
    "HTML(addToggle())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## variables for this project\n",
    "\n",
    "samples_in=\"../data/sna/SNA_4.0_plant.json\"\n",
    "results_dir = \"../results/sna/\"\n",
    "dataframe_out=results_dir+\"dataframes_sna.pkl\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check whether or not the dataframes exist\n",
    "\n",
    "subdir=\"./\"\n",
    "dataframefile=dataframe_out\n",
    "\n",
    "if not os.path.isfile(dataframefile):\n",
    "    print \"calling the notebook that loads the data\"\n",
    "    %run download_cfg_for_sna.ipynb\n",
    "with open(os.path.join(subdir, dataframefile)) as f:\n",
    "    dataframes = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# peak at the data in frame 0 \n",
    "frame=dataframes[0][\"dataframe\"]\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recalculate CV\n",
    "# rank the glycans by RFU\n",
    "frame[\"CV\"]=100*frame[\"STDEV\"]/frame[\"RFU\"]\n",
    "maxrfu=frame[\"RFU\"].max()\n",
    "frame[\"rank\"]=100*frame[\"RFU\"]/maxrfu\n",
    "frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose data to work with \n",
    "frames=[dataframes[0][\"dataframe\"],dataframes[1][\"dataframe\"], dataframes[2][\"dataframe\"]]\n",
    "sample_keys=[dataframes[0][\"sample\"].encode('utf-8'),dataframes[1][\"sample\"].encode('utf-8'), dataframes[2][\"sample\"].encode('utf-8')]\n",
    "\n",
    "# recalculate CV and rank the glycans by RFU\n",
    "for frame in frames:\n",
    "    frame[\"CV\"]=100*frame[\"STDEV\"]/frame[\"RFU\"]\n",
    "    maxrfu=frame[\"RFU\"].max()\n",
    "    frame[\"rank\"]=100*frame[\"RFU\"]/maxrfu\n",
    "\n",
    "# peak at all frames\n",
    "result = pd.concat(frames, keys=sample_keys)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFU, zscore and p-value\n",
    "Must convert from z-score to p-value.\n",
    "In the paper, the RFU is summed across all datasets and this is used to calculate a p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate rank, %CV for all frames, z-score, p-value for all frames and sort by average rank\n",
    "RFU=\"RFU\"\n",
    "for aframe in frames:\n",
    "    aframe[\"CV\"]=100*aframe[\"STDEV\"]/aframe[\"RFU\"]\n",
    "    maxrfu=aframe[\"RFU\"].max()\n",
    "    aframe[\"rank\"]=100*aframe[\"RFU\"]/maxrfu\n",
    "    aframe[\"z-score\"]=stats.zscore(aframe[RFU])\n",
    "    aframe[\"p-value\"]=1- 0.5 * (1 + erf(aframe[\"z-score\"] / sqrt(2)))\n",
    "\n",
    "#. merge_frames\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on=['Structure','Chart Number']), frames)\n",
    "df_final\n",
    "\n",
    "#. calculate the average rank\n",
    "\n",
    "df_final[\"avg_rank\"]=df_final.filter(regex=(\"rank.*\")).sum(axis=1)/df_final.filter(regex=(\"rank.*\")).shape[1]  # http://stackoverflow.com/questions/30808430/how-to-select-columns-from-dataframe-by-regex\n",
    "\n",
    "\n",
    "#. calculate the summed RFU\n",
    "\n",
    "df_final[\"summed_RFU\"]=df_final.filter(regex=(\"RFU.*\")).sum(axis=1)\n",
    "\n",
    "\n",
    "#. calculate the z-score and p-value for the summed RFU\n",
    "df_final.head()\n",
    "df_final[\"summed_RFU_z-score\"]=stats.zscore(df_final[\"summed_RFU\"])\n",
    "df_final[\"summed_RFU_p-value\"]=1- 0.5 * (1 + erf(df_final[\"summed_RFU_z-score\"] / sqrt(2)))\n",
    "df_final.sort_values(\"avg_rank\",ascending=False)\n",
    "#frames_RFU_sum[\"p-value_them\"]=1- 0.5 * (1 + erf(frames_RFU_sum[\"stats_z-score\"] / sqrt(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In agreement with p values from [paper](../data/sna/sna_z-score.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract only the high binders and compare to paper\n",
    "\n",
    "- Check agreement using assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#. extract the high binders. p-value < 0.15\n",
    "\n",
    "df_final_high_binders = df_final[df_final[\"summed_RFU_p-value\"] <0.15]\n",
    "df_final_high_binders.sort_values(\"avg_rank\",ascending=False)\n",
    "#print df_final_high_binders.shape\n",
    "high_binders_from_paper=[353,256,327,341,259,343,54,315,52,314,51,46,258,275,260,325,257,321,53,342,255,407,300,292,340,373]\n",
    "assert df_final_high_binders.shape[0]==len(high_binders_from_paper)\n",
    "assert set(df_final_high_binders[\"Chart Number\"])==set(high_binders_from_paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final[df_final[\"Chart Number\"]==340]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the % CV?\n",
    "See https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3097418/\n",
    "\n",
    "There are three statements made about %CV\n",
    " - >50% the data should be disregarded\n",
    " - >20-40% the CV is high and the results for binding may not be reliable\n",
    " - >30% when binding is low with high imprecision the data are classified as inconclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparing % CV with the high binders from z-scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#. lets pull out any %CV column of df_final and ensure CV <20\n",
    "#.. remember there are negative CV in this sample, exclude these \n",
    "df_cv_20=df_final.filter(regex=(\"%CV.*\")) <=20\n",
    "df_cv_0=df_final.filter(regex=(\"%CV.*\")) >0\n",
    "\n",
    "df_cv_0_20=(df_cv_0 & df_cv_20)\n",
    "\n",
    "\n",
    "#print df_cv_0_20.head(340)\n",
    "andmask=df_cv_0_20[\"%CV_x\"]&df_cv_0_20[\"%CV_y\"]&df_cv_0_20[\"%CV\"]\n",
    "ormask=df_cv_0_20[\"%CV_x\"]|df_cv_0_20[\"%CV_y\"]|df_cv_0_20[\"%CV\"]\n",
    "#mask\n",
    "\n",
    "glycan_ids_cv_20=df_final[\"Chart Number\"][andmask]\n",
    "print len(glycan_ids_cv_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final_high_binders.sort_values(\"avg_rank\",ascending=False)[\"Chart Number\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final[andmask].sort_values(\"avg_rank\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#. any in common with high_binders_from_paper (intersection)\n",
    "in_common=set(high_binders_from_paper)&set(glycan_ids_cv_20)\n",
    "print \"Common:\", in_common, len(in_common)\n",
    "# differences\n",
    "print \"Highbind-CV: \",set(high_binders_from_paper)-set(glycan_ids_cv_20), len(set(high_binders_from_paper)-set(glycan_ids_cv_20))\n",
    "print \"CV- Highbind: \",set(glycan_ids_cv_20)-set(high_binders_from_paper), len(set(glycan_ids_cv_20)-set(high_binders_from_paper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see http://pandas.pydata.org/pandas-docs/stable/options.html for pandas options\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('max_columns', 100)\n",
    "df_final[df_final[\"Chart Number\"]==340]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### These does not agree. why? \n",
    "\n",
    "- an example that is included in highbinder is Chart Number 340. This has a low CV for one experiment, a negative CV for another and a >50 CV for the final. \n",
    "\n",
    "Maybe use %CV as a preparsing and then the z-score? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A consideration of the glycans by %CV for the first frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make various views of frame 0 based on the %CV\n",
    "df_cv_50 = frame[frame.CV <50]\n",
    "df_cv_30 = frame[frame.CV <30]\n",
    "df_cv_20 = frame[frame.CV <20]\n",
    "df_cv_20_0 = df_cv_20[df_cv_20.CV>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot rank v %CV\n",
    "# plot comparison of different %CV subsets\n",
    "plt.figure()\n",
    "df_cv_20[\"CV\"].plot(legend=True, title='%CV<=20%')\n",
    "df_cv_20[\"STDEV\"].plot(secondary_y=True, style='g', legend=True)\n",
    "plt.figure()\n",
    "df_cv_20_0[\"CV\"].plot(legend=True, title='0<%CV<=20%')\n",
    "df_cv_20_0[\"STDEV\"].plot(secondary_y=True, style='g', legend=True)\n",
    "plt.figure()\n",
    "df_cv_30[\"CV\"].plot(legend=True, title='%CV<=30%')\n",
    "df_cv_30[\"STDEV\"].plot(secondary_y=True, style='g', legend=True)\n",
    "plt.figure()\n",
    "df_cv_50[\"CV\"].plot(legend=True, title='%CV<=50%')\n",
    "df_cv_50[\"STDEV\"].plot(secondary_y=True, style='g', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use 0<cv<20 and order by rank\n",
    "pd.set_option('max_rows', 300)\n",
    "df_cv_20_0.sort_values(\"rank\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
